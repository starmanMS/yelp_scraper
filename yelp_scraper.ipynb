{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36416cf0819e43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from afinn import Afinn\n",
    "from nrclex import NRCLex\n",
    "\n",
    "# Initialize AFINN for sentiment analysis\n",
    "afinn = Afinn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebbfe26316b7da71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T03:33:22.000111Z",
     "start_time": "2024-11-04T03:33:21.975724Z"
    }
   },
   "outputs": [],
   "source": [
    "class YelpScraper:\n",
    "    def __init__(self, api_key, location='Boston, MA', num_pages=3):\n",
    "        self.api_key = api_key\n",
    "        self.location = location\n",
    "        self.num_pages = num_pages\n",
    "        self.base_url = 'https://www.yelp.com/search'\n",
    "\n",
    "    def get_yelp_urls(self, search_query):\n",
    "        \"\"\"Generate Yelp search URLs for the given search query.\"\"\"\n",
    "        search_query_encoded = search_query.replace(' ', '%20')\n",
    "        location_encoded = self.location.replace(' ', '%20')\n",
    "\n",
    "        return [\n",
    "            f\"{self.base_url}?find_desc={search_query_encoded}&find_loc={location_encoded}&start={page * 10}\"\n",
    "            for page in range(self.num_pages)\n",
    "        ]\n",
    "\n",
    "    def fetch_page_content(self, url, retries=3):\n",
    "        \"\"\"Fetch page content with retries using a rotating proxy service.\"\"\"\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                proxy_url = f\"https://api.scraperapi.com/?api_key={self.api_key}&url={url}&country_code=us\"\n",
    "                response = requests.get(proxy_url)\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    print(f\"Success: Fetched content for {url}\")\n",
    "                    return response.text\n",
    "                elif response.status_code in [403, 429]:\n",
    "                    print(\"Access denied, retrying with delay...\")\n",
    "                    time.sleep(random.uniform(10, 20))\n",
    "                elif response.status_code == 500:\n",
    "                    print(\"Server error (500). Retrying after a longer delay...\")\n",
    "                    time.sleep(random.uniform(20, 30))\n",
    "                else:\n",
    "                    print(f\"Unexpected status code {response.status_code} for {url}\")\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Error fetching {url}: {e}\")\n",
    "                time.sleep(random.uniform(5, 10))\n",
    "        return None\n",
    "\n",
    "    def scrape_reviews(self, search_query):\n",
    "        \"\"\"Scrape reviews from Yelp based on the search query.\"\"\"\n",
    "        urls = self.get_yelp_urls(search_query)\n",
    "        reviews_data = []\n",
    "\n",
    "        for url in urls:\n",
    "            print(f\"Fetching URL: {url}\")\n",
    "            page_content = self.fetch_page_content(url)\n",
    "            if page_content:\n",
    "                soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "                restaurant_name = self.extract_restaurant_name(soup)\n",
    "                review_texts = self.extract_reviews(soup)\n",
    "\n",
    "                for review in review_texts:\n",
    "                    reviews_data.append((restaurant_name, review))\n",
    "\n",
    "                time.sleep(random.uniform(10, 15))\n",
    "\n",
    "        return reviews_data\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_restaurant_name(soup):\n",
    "        \"\"\"Extract restaurant name from page content.\"\"\"\n",
    "        restaurant_name_tag = soup.find('h3', class_='y-css-hcgwj4')\n",
    "        return restaurant_name_tag.get_text(strip=True) if restaurant_name_tag else \"Unknown\"\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_reviews(soup):\n",
    "        \"\"\"Extract review texts from page content.\"\"\"\n",
    "        review_containers = soup.find_all('p', class_='y-css-1d5urxi')\n",
    "        return [review.get_text(strip=True) for review in review_containers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e93a319c17af144",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T03:25:53.923895Z",
     "start_time": "2024-11-04T03:25:53.917640Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReviewAnalyzer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def analyze_sentiment_afinn(reviews):\n",
    "        \"\"\"Perform AFINN sentiment analysis on reviews.\"\"\"\n",
    "        sentiment_data = []\n",
    "        for restaurant, review in reviews:\n",
    "            score = afinn.score(review)\n",
    "            sentiment_label = 'positive' if score > 0 else ('negative' if score < 0 else 'neutral')\n",
    "            sentiment_data.append((review, score, sentiment_label, restaurant))\n",
    "        return sentiment_data\n",
    "\n",
    "    @staticmethod\n",
    "    def analyze_emotions_nrc(reviews):\n",
    "        \"\"\"Perform NRC emotion analysis on reviews.\"\"\"\n",
    "        emotions_data = []\n",
    "        for restaurant, review in reviews:\n",
    "            nrc_result = NRCLex(review)\n",
    "            top_emotions = nrc_result.top_emotions\n",
    "            emotions_data.append((review, top_emotions, restaurant))\n",
    "        return emotions_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91107f8d024a3a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T03:33:02.698342Z",
     "start_time": "2024-11-04T03:33:02.690339Z"
    }
   },
   "outputs": [],
   "source": [
    "class FileWriter:\n",
    "    @staticmethod\n",
    "    def save_sentiment_results(sentiment_results, filename='sentiment_analysis_results.csv'):\n",
    "        \"\"\"Save sentiment analysis results to a CSV file and print to terminal.\"\"\"\n",
    "        sentiment_df = pd.DataFrame(sentiment_results, columns=['Review', 'Score', 'Sentiment', 'Restaurant'])\n",
    "        sentiment_df.to_csv(filename, index=False)\n",
    "        print(f\"Sentiment analysis results saved to {filename}\")\n",
    "        print(sentiment_df)  # Print the DataFrame to the terminal\n",
    "\n",
    "    @staticmethod\n",
    "    def save_emotions_results(emotions_results, filename='emotions_analysis.txt'):\n",
    "        \"\"\"Save emotion analysis results to a text file and print to terminal.\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            for review, emotions, restaurant in emotions_results:\n",
    "                f.write(f\"Restaurant: {restaurant}\\nReview: {review}\\nEmotions: {emotions}\\n\\n\")\n",
    "                # Print each entry to the terminal\n",
    "                print(f\"Restaurant: {restaurant}\\nReview: {review}\\nEmotions: {emotions}\\n\")\n",
    "\n",
    "        print(f\"Emotion analysis results saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da58dd4ef496e994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T03:33:27.626137Z",
     "start_time": "2024-11-04T03:33:27.620976Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    api_key = '9a09e6ab229bda75b8b8da7e4ecbf587'  # Replace with your ScraperAPI key\n",
    "    search_query = 'restaurants'\n",
    "\n",
    "    # Initialize Scraper and Analyzer\n",
    "    scraper = YelpScraper(api_key=api_key)\n",
    "    analyzer = ReviewAnalyzer()\n",
    "    file_writer = FileWriter()\n",
    "\n",
    "    # Scrape reviews\n",
    "    reviews = scraper.scrape_reviews(search_query)\n",
    "\n",
    "    # AFINN Sentiment Analysis\n",
    "    sentiment_results = analyzer.analyze_sentiment_afinn(reviews)\n",
    "    file_writer.save_sentiment_results(sentiment_results)\n",
    "\n",
    "    # NRC Emotion Analysis\n",
    "    emotions_results = analyzer.analyze_emotions_nrc(reviews)\n",
    "    file_writer.save_emotions_results(emotions_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
